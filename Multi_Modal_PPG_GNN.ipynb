{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "âœ… All dependencies installed successfully!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  Ã— Getting requirements to build wheel did not run successfully.\n",
      "  â”‚ exit code: 1\n",
      "  â•°â”€> [23 lines of output]\n",
      "      Traceback (most recent call last):\n",
      "        File \u001b[35m\"c:\\Users\\Ajayj\\miniconda3\\envs\\transECG\\Lib\\site-packages\\pip\\_vendor\\pyproject_hooks\\_in_process\\_in_process.py\"\u001b[0m, line \u001b[35m389\u001b[0m, in \u001b[35m<module>\u001b[0m\n",
      "          \u001b[31mmain\u001b[0m\u001b[1;31m()\u001b[0m\n",
      "          \u001b[31m~~~~\u001b[0m\u001b[1;31m^^\u001b[0m\n",
      "        File \u001b[35m\"c:\\Users\\Ajayj\\miniconda3\\envs\\transECG\\Lib\\site-packages\\pip\\_vendor\\pyproject_hooks\\_in_process\\_in_process.py\"\u001b[0m, line \u001b[35m373\u001b[0m, in \u001b[35mmain\u001b[0m\n",
      "          json_out[\"return_val\"] = \u001b[31mhook\u001b[0m\u001b[1;31m(**hook_input[\"kwargs\"])\u001b[0m\n",
      "                                   \u001b[31m~~~~\u001b[0m\u001b[1;31m^^^^^^^^^^^^^^^^^^^^^^^^\u001b[0m\n",
      "        File \u001b[35m\"c:\\Users\\Ajayj\\miniconda3\\envs\\transECG\\Lib\\site-packages\\pip\\_vendor\\pyproject_hooks\\_in_process\\_in_process.py\"\u001b[0m, line \u001b[35m143\u001b[0m, in \u001b[35mget_requires_for_build_wheel\u001b[0m\n",
      "          return hook(config_settings)\n",
      "        File \u001b[35m\"C:\\Users\\Ajayj\\AppData\\Local\\Temp\\pip-build-env-jaayk44u\\overlay\\Lib\\site-packages\\setuptools\\build_meta.py\"\u001b[0m, line \u001b[35m331\u001b[0m, in \u001b[35mget_requires_for_build_wheel\u001b[0m\n",
      "          return \u001b[31mself._get_build_requires\u001b[0m\u001b[1;31m(config_settings, requirements=[])\u001b[0m\n",
      "                 \u001b[31m~~~~~~~~~~~~~~~~~~~~~~~~\u001b[0m\u001b[1;31m^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[0m\n",
      "        File \u001b[35m\"C:\\Users\\Ajayj\\AppData\\Local\\Temp\\pip-build-env-jaayk44u\\overlay\\Lib\\site-packages\\setuptools\\build_meta.py\"\u001b[0m, line \u001b[35m301\u001b[0m, in \u001b[35m_get_build_requires\u001b[0m\n",
      "          \u001b[31mself.run_setup\u001b[0m\u001b[1;31m()\u001b[0m\n",
      "          \u001b[31m~~~~~~~~~~~~~~\u001b[0m\u001b[1;31m^^\u001b[0m\n",
      "        File \u001b[35m\"C:\\Users\\Ajayj\\AppData\\Local\\Temp\\pip-build-env-jaayk44u\\overlay\\Lib\\site-packages\\setuptools\\build_meta.py\"\u001b[0m, line \u001b[35m512\u001b[0m, in \u001b[35mrun_setup\u001b[0m\n",
      "          \u001b[31msuper().run_setup\u001b[0m\u001b[1;31m(setup_script=setup_script)\u001b[0m\n",
      "          \u001b[31m~~~~~~~~~~~~~~~~~\u001b[0m\u001b[1;31m^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[0m\n",
      "        File \u001b[35m\"C:\\Users\\Ajayj\\AppData\\Local\\Temp\\pip-build-env-jaayk44u\\overlay\\Lib\\site-packages\\setuptools\\build_meta.py\"\u001b[0m, line \u001b[35m317\u001b[0m, in \u001b[35mrun_setup\u001b[0m\n",
      "          \u001b[31mexec\u001b[0m\u001b[1;31m(code, locals())\u001b[0m\n",
      "          \u001b[31m~~~~\u001b[0m\u001b[1;31m^^^^^^^^^^^^^^^^\u001b[0m\n",
      "        File \u001b[35m\"<string>\"\u001b[0m, line \u001b[35m8\u001b[0m, in \u001b[35m<module>\u001b[0m\n",
      "      \u001b[1;35mModuleNotFoundError\u001b[0m: \u001b[35mNo module named 'torch'\u001b[0m\n",
      "      [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "error: subprocess-exited-with-error\n",
      "\n",
      "Ã— Getting requirements to build wheel did not run successfully.\n",
      "â”‚ exit code: 1\n",
      "â•°â”€> See above for output.\n",
      "\n",
      "note: This error originates from a subprocess, and is likely not a problem with pip.\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# DEPENDENCY INSTALLATION\n",
    "# Run this cell once to install all required packages for GNN\n",
    "# ============================================================================\n",
    "\n",
    "# Core dependencies\n",
    "%pip install numpy scipy scikit-learn pandas matplotlib seaborn -q\n",
    "\n",
    "# PyTorch (CPU version - change to GPU version if you have CUDA)\n",
    "%pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cpu -q\n",
    "\n",
    "# PyTorch Geometric and dependencies\n",
    "%pip install torch-geometric -q\n",
    "%pip install torch-scatter torch-sparse torch-cluster torch-spline-conv -f https://data.pyg.org/whl/torch-2.0.0+cpu.html -q\n",
    "\n",
    "print(\"âœ… All dependencies installed successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Loaded S1: BVP (589568, 1), ACC (294784, 3), HR (4603,), Activity (36848, 1)\n",
      "âœ… Loaded S2: BVP (525120, 1), ACC (262560, 3), HR (4099,), Activity (32820, 1)\n",
      "âœ… Loaded S3: BVP (559424, 1), ACC (279712, 3), HR (4367,), Activity (34964, 1)\n",
      "âœ… Loaded S4: BVP (585600, 1), ACC (292800, 3), HR (4572,), Activity (36600, 1)\n",
      "âœ… Loaded S5: BVP (595520, 1), ACC (297760, 3), HR (4649,), Activity (37220, 1)\n",
      "âœ… Loaded S6: BVP (336000, 1), ACC (168000, 3), HR (2622,), Activity (21000, 1)\n",
      "âœ… Loaded S7: BVP (597952, 1), ACC (298976, 3), HR (4668,), Activity (37372, 1)\n",
      "âœ… Loaded S8: BVP (517120, 1), ACC (258560, 3), HR (4037,), Activity (32320, 1)\n",
      "âœ… Loaded S9: BVP (547840, 1), ACC (273920, 3), HR (4277,), Activity (34240, 1)\n",
      "âœ… Loaded S10: BVP (681472, 1), ACC (340736, 3), HR (5321,), Activity (42592, 1)\n",
      "âœ… Loaded S11: BVP (579072, 1), ACC (289536, 3), HR (4521,), Activity (36192, 1)\n",
      "âœ… Loaded S12: BVP (506496, 1), ACC (253248, 3), HR (3954,), Activity (31656, 1)\n",
      "âœ… Loaded S13: BVP (584704, 1), ACC (292352, 3), HR (4565,), Activity (36544, 1)\n",
      "âœ… Loaded S14: BVP (573312, 1), ACC (286656, 3), HR (4476,), Activity (35832, 1)\n",
      "âœ… Loaded S15: BVP (508096, 1), ACC (254048, 3), HR (3966,), Activity (31756, 1)\n",
      "\n",
      "Keys for S1: dict_keys(['BVP', 'ACC', 'HR', 'Activity'])\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "# Path to your dataset\n",
    "DATASET_PATH = r\"C:\\Users\\Ajayj\\Documents\\ResearchData\\PPG_Data\\PPG_FieldStudy\"\n",
    "\n",
    "def load_ppg_dataset(dataset_path):\n",
    "    \"\"\"\n",
    "    Load synchronized PPG dataset from all subject .pkl files.\n",
    "    \n",
    "    Returns:\n",
    "        dataset (dict): \n",
    "            {\n",
    "              \"S1\": {\"BVP\": np.array, \"ACC\": np.array, \"HR\": np.array, \"Activity\": np.array},\n",
    "              \"S2\": {...},\n",
    "              ...\n",
    "            }\n",
    "    \"\"\"\n",
    "    dataset = {}\n",
    "    \n",
    "    for subj in range(1, 16):  # Subjects S1 ... S15\n",
    "        subj_id = f\"S{subj}\"\n",
    "        subj_folder = os.path.join(dataset_path, subj_id)\n",
    "        pkl_file = os.path.join(subj_folder, f\"{subj_id}.pkl\")\n",
    "        \n",
    "        if not os.path.exists(pkl_file):\n",
    "            print(f\"âš ï¸ Missing file: {pkl_file}\")\n",
    "            continue\n",
    "        \n",
    "        # Load the .pkl file\n",
    "        with open(pkl_file, \"rb\") as f:\n",
    "            data = pickle.load(f, encoding=\"latin1\")  # latin1 ensures compatibility\n",
    "        \n",
    "        # Extract signals + labels\n",
    "        bvp = np.array(data[\"signal\"][\"wrist\"][\"BVP\"])   # 64 Hz PPG\n",
    "        acc = np.array(data[\"signal\"][\"wrist\"][\"ACC\"])   # 32 Hz ACC (3D)\n",
    "        hr  = np.array(data[\"label\"])                    # ECG-derived HR (windowed)\n",
    "        act = np.array(data[\"activity\"])                 # Activity ID\n",
    "        \n",
    "        dataset[subj_id] = {\n",
    "            \"BVP\": bvp,\n",
    "            \"ACC\": acc,\n",
    "            \"HR\": hr,\n",
    "            \"Activity\": act\n",
    "        }\n",
    "        \n",
    "        print(f\"âœ… Loaded {subj_id}: BVP {bvp.shape}, ACC {acc.shape}, HR {hr.shape}, Activity {act.shape}\")\n",
    "    \n",
    "    return dataset\n",
    "\n",
    "# Run loader\n",
    "dataset = load_ppg_dataset(DATASET_PATH)\n",
    "\n",
    "# Example: check S1 keys\n",
    "print(\"\\nKeys for S1:\", dataset[\"S1\"].keys())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… S1: (4603, 512, 1), (4603, 256, 3), HR (4603,)\n",
      "âœ… S2: (4099, 512, 1), (4099, 256, 3), HR (4099,)\n",
      "âœ… S3: (4367, 512, 1), (4367, 256, 3), HR (4367,)\n",
      "âœ… S4: (4572, 512, 1), (4572, 256, 3), HR (4572,)\n",
      "âœ… S5: (4649, 512, 1), (4649, 256, 3), HR (4649,)\n",
      "âœ… S6: (2622, 512, 1), (2622, 256, 3), HR (2622,)\n",
      "âœ… S7: (4668, 512, 1), (4668, 256, 3), HR (4668,)\n",
      "âœ… S8: (4037, 512, 1), (4037, 256, 3), HR (4037,)\n",
      "âœ… S9: (4277, 512, 1), (4277, 256, 3), HR (4277,)\n",
      "âœ… S10: (5321, 512, 1), (5321, 256, 3), HR (5321,)\n",
      "âœ… S11: (4521, 512, 1), (4521, 256, 3), HR (4521,)\n",
      "âœ… S12: (3954, 512, 1), (3954, 256, 3), HR (3954,)\n",
      "âœ… S13: (4565, 512, 1), (4565, 256, 3), HR (4565,)\n",
      "âœ… S14: (4476, 512, 1), (4476, 256, 3), HR (4476,)\n",
      "âœ… S15: (3966, 512, 1), (3966, 256, 3), HR (3966,)\n",
      "\n",
      "S1 processed shapes:\n",
      "BVP: (4603, 512, 1)\n",
      "ACC: (4603, 256, 3)\n",
      "HR: (4603,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def segment_signal(signal, window_size, step_size):\n",
    "    \"\"\"\n",
    "    Segment 1D or 2D signal into overlapping windows.\n",
    "    \n",
    "    Args:\n",
    "        signal (np.array): shape (N,) or (N, D)\n",
    "        window_size (int): number of samples per window\n",
    "        step_size (int): number of samples to move the window\n",
    "    \n",
    "    Returns:\n",
    "        windows (np.array): shape (#windows, window_size, D)\n",
    "    \"\"\"\n",
    "    n_samples = signal.shape[0]\n",
    "    if signal.ndim == 1:\n",
    "        signal = signal.reshape(-1, 1)\n",
    "    n_dims = signal.shape[1]\n",
    "    \n",
    "    windows = []\n",
    "    for start in range(0, n_samples - window_size + 1, step_size):\n",
    "        end = start + window_size\n",
    "        windows.append(signal[start:end])\n",
    "    return np.array(windows)\n",
    "\n",
    "def preprocess_dataset(dataset):\n",
    "    \"\"\"\n",
    "    For each subject, segment BVP and ACC signals into 8s windows\n",
    "    with 2s shift and align them with HR labels.\n",
    "    \n",
    "    Returns:\n",
    "        processed (dict): {subject: {\"BVP\": ..., \"ACC\": ..., \"HR\": ..., \"Activity\": ...}}\n",
    "    \"\"\"\n",
    "    processed = {}\n",
    "    \n",
    "    # Parameters\n",
    "    bvp_fs = 64   # Hz\n",
    "    acc_fs = 32   # Hz\n",
    "    win_time = 8  # seconds\n",
    "    step_time = 2 # seconds\n",
    "    \n",
    "    bvp_win = win_time * bvp_fs   # 512 samples\n",
    "    bvp_step = step_time * bvp_fs # 128 samples\n",
    "    \n",
    "    acc_win = win_time * acc_fs   # 256 samples\n",
    "    acc_step = step_time * acc_fs # 64 samples\n",
    "    \n",
    "    for subj, data in dataset.items():\n",
    "        bvp = data[\"BVP\"].squeeze()    # (N,)\n",
    "        acc = data[\"ACC\"]              # (N, 3)\n",
    "        hr  = data[\"HR\"]               # (#windows,)\n",
    "        act = data[\"Activity\"]         # (#activity_samples, 1) at 4 Hz\n",
    "        \n",
    "        # Segment BVP + ACC\n",
    "        bvp_windows = segment_signal(bvp, bvp_win, bvp_step)\n",
    "        acc_windows = segment_signal(acc, acc_win, acc_step)\n",
    "        \n",
    "        # Align to HR length\n",
    "        min_len = min(len(hr), len(bvp_windows), len(acc_windows))\n",
    "        bvp_windows = bvp_windows[:min_len]\n",
    "        acc_windows = acc_windows[:min_len]\n",
    "        hr = hr[:min_len]\n",
    "        \n",
    "        processed[subj] = {\n",
    "            \"BVP\": bvp_windows,   # (N_windows, 512, 1)\n",
    "            \"ACC\": acc_windows,   # (N_windows, 256, 3)\n",
    "            \"HR\": hr,             # (N_windows,)\n",
    "            \"Activity\": act       # Keep raw activity for now\n",
    "        }\n",
    "        \n",
    "        print(f\"âœ… {subj}: {bvp_windows.shape}, {acc_windows.shape}, HR {hr.shape}\")\n",
    "    \n",
    "    return processed\n",
    "\n",
    "# Run preprocessing\n",
    "processed_dataset = preprocess_dataset(dataset)\n",
    "\n",
    "# Example check\n",
    "print(\"\\nS1 processed shapes:\")\n",
    "print(\"BVP:\", processed_dataset[\"S1\"][\"BVP\"].shape)\n",
    "print(\"ACC:\", processed_dataset[\"S1\"][\"ACC\"].shape)\n",
    "print(\"HR:\", processed_dataset[\"S1\"][\"HR\"].shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature dataset shape: (64697, 28)\n",
      "Labels shape: (64697,)\n",
      "Example feature vector length: 28\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "from scipy.signal import welch\n",
    "\n",
    "def extract_bvp_features(window, fs=64):\n",
    "    \"\"\"Extract time + frequency features from one BVP window (512 samples).\"\"\"\n",
    "    feats = []\n",
    "    \n",
    "    # Time-domain\n",
    "    feats.append(np.mean(window))\n",
    "    feats.append(np.std(window))\n",
    "    feats.append(np.min(window))\n",
    "    feats.append(np.max(window))\n",
    "    feats.append(stats.skew(window))\n",
    "    feats.append(stats.kurtosis(window))\n",
    "    \n",
    "    # Frequency-domain (Welch PSD)\n",
    "    freqs, psd = welch(window, fs=fs, nperseg=256)\n",
    "    \n",
    "    # Bands: low freq (0.04-0.15 Hz), high freq (0.15-0.4 Hz)\n",
    "    lf_band = np.logical_and(freqs >= 0.04, freqs < 0.15)\n",
    "    hf_band = np.logical_and(freqs >= 0.15, freqs < 0.4)\n",
    "    \n",
    "    lf_power = np.sum(psd[lf_band])\n",
    "    hf_power = np.sum(psd[hf_band])\n",
    "    \n",
    "    feats.append(lf_power)\n",
    "    feats.append(hf_power)\n",
    "    \n",
    "    # Dominant frequency\n",
    "    dom_idx = np.argmax(psd)\n",
    "    feats.append(freqs[dom_idx])\n",
    "    feats.append(psd[dom_idx])\n",
    "    \n",
    "    return np.array(feats)\n",
    "\n",
    "def safe_corrcoef(x, y):\n",
    "    if np.std(x) == 0 or np.std(y) == 0:\n",
    "        return 0.0\n",
    "    return np.corrcoef(x, y)[0,1]\n",
    "\n",
    "def extract_acc_features(window, fs=32):\n",
    "    \"\"\"Extract motion features from one ACC window (256Ã—3).\"\"\"\n",
    "    feats = []\n",
    "    for i in range(3):  # x, y, z axes\n",
    "        axis = window[:, i]\n",
    "        feats.append(np.mean(axis))\n",
    "        feats.append(np.std(axis))\n",
    "        feats.append(np.min(axis))\n",
    "        feats.append(np.max(axis))\n",
    "        feats.append(np.sum(axis**2))  # energy\n",
    "    \n",
    "    # Cross-axis correlations\n",
    "    feats.append(safe_corrcoef(window[:,0], window[:,1]))\n",
    "    feats.append(safe_corrcoef(window[:,0], window[:,2]))\n",
    "    feats.append(safe_corrcoef(window[:,1], window[:,2]))\n",
    "    \n",
    "    return np.array(feats)\n",
    "\n",
    "def build_feature_dataset(processed_dataset):\n",
    "    \"\"\"\n",
    "    Extract features from BVP + ACC for all subjects.\n",
    "    Returns:\n",
    "        X (np.array): features [N_windows, N_features]\n",
    "        y (np.array): HR labels [N_windows]\n",
    "        subjects (list): subject IDs per window\n",
    "    \"\"\"\n",
    "    X, y, subjects = [], [], []\n",
    "    \n",
    "    for subj, data in processed_dataset.items():\n",
    "        bvp_windows = data[\"BVP\"]\n",
    "        acc_windows = data[\"ACC\"]\n",
    "        hr_labels = data[\"HR\"]\n",
    "        \n",
    "        for i in range(len(hr_labels)):\n",
    "            bvp_feats = extract_bvp_features(bvp_windows[i].squeeze())\n",
    "            acc_feats = extract_acc_features(acc_windows[i])\n",
    "            feats = np.concatenate([bvp_feats, acc_feats])\n",
    "            \n",
    "            X.append(feats)\n",
    "            y.append(hr_labels[i])\n",
    "            subjects.append(subj)\n",
    "    \n",
    "    return np.array(X), np.array(y), subjects\n",
    "\n",
    "# Run feature extraction\n",
    "X, y, subj_ids = build_feature_dataset(processed_dataset)\n",
    "\n",
    "print(\"Feature dataset shape:\", X.shape)\n",
    "print(\"Labels shape:\", y.shape)\n",
    "print(\"Example feature vector length:\", X.shape[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: (51757, 28) Test set: (12940, 28)\n",
      "âœ… Dataset ready for modeling\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def prepare_train_test(X, y, test_size=0.2, random_state=42):\n",
    "    \"\"\"\n",
    "    Normalize features and split into train/test sets.\n",
    "    \"\"\"\n",
    "    # Normalize features\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    \n",
    "    # Train/test split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X_scaled, y, test_size=test_size, random_state=random_state\n",
    "    )\n",
    "    \n",
    "    print(\"Train set:\", X_train.shape, \"Test set:\", X_test.shape)\n",
    "    return X_train, X_test, y_train, y_test, scaler\n",
    "\n",
    "# Run preparation\n",
    "X_train, X_test, y_train, y_test, scaler = prepare_train_test(X, y)\n",
    "\n",
    "print(\"âœ… Dataset ready for modeling\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Ajayj\\miniconda3\\envs\\transECG\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building k-NN graph with k=10...\n",
      "âœ… Train graph: 51757 nodes, 517570 edges\n",
      "âœ… Test graph: 12940 nodes, 129400 edges\n",
      "\n",
      "Train data shape: torch.Size([51757, 28])\n",
      "Test data shape: torch.Size([12940, 28])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.data import Data\n",
    "from sklearn.neighbors import kneighbors_graph\n",
    "import numpy as np\n",
    "\n",
    "def build_knn_graph(X_train, X_test, y_train, y_test, k=10):\n",
    "    \"\"\"\n",
    "    Build k-NN graph from feature vectors for GNN training.\n",
    "    \n",
    "    Args:\n",
    "        X_train: Training features (N_train, num_features)\n",
    "        X_test: Test features (N_test, num_features)\n",
    "        y_train: Training labels (HR values)\n",
    "        y_test: Test labels (HR values)\n",
    "        k: Number of nearest neighbors\n",
    "    \n",
    "    Returns:\n",
    "        train_data: PyTorch Geometric Data object for training\n",
    "        test_data: PyTorch Geometric Data object for testing\n",
    "    \"\"\"\n",
    "    print(f\"Building k-NN graph with k={k}...\")\n",
    "    \n",
    "    # Build train graph\n",
    "    # Create k-NN adjacency matrix (mode='connectivity' gives binary adjacency)\n",
    "    train_adj = kneighbors_graph(X_train, k, mode='connectivity', include_self=False)\n",
    "    train_edge_index = torch.tensor(np.array(train_adj.nonzero()), dtype=torch.long)\n",
    "    \n",
    "    # Convert to PyG Data object\n",
    "    train_data = Data(\n",
    "        x=torch.tensor(X_train, dtype=torch.float32),\n",
    "        edge_index=train_edge_index,\n",
    "        y=torch.tensor(y_train, dtype=torch.float32).unsqueeze(1)\n",
    "    )\n",
    "    \n",
    "    # Build test graph\n",
    "    test_adj = kneighbors_graph(X_test, k, mode='connectivity', include_self=False)\n",
    "    test_edge_index = torch.tensor(np.array(test_adj.nonzero()), dtype=torch.long)\n",
    "    \n",
    "    test_data = Data(\n",
    "        x=torch.tensor(X_test, dtype=torch.float32),\n",
    "        edge_index=test_edge_index,\n",
    "        y=torch.tensor(y_test, dtype=torch.float32).unsqueeze(1)\n",
    "    )\n",
    "    \n",
    "    print(f\"âœ… Train graph: {train_data.num_nodes} nodes, {train_data.num_edges} edges\")\n",
    "    print(f\"âœ… Test graph: {test_data.num_nodes} nodes, {test_data.num_edges} edges\")\n",
    "    \n",
    "    return train_data, test_data\n",
    "\n",
    "# Build k-NN graphs for GNN\n",
    "train_data, test_data = build_knn_graph(X_train, X_test, y_train, y_test, k=10)\n",
    "\n",
    "print(f\"\\nTrain data shape: {train_data.x.shape}\")\n",
    "print(f\"Test data shape: {test_data.x.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch_geometric.nn import GATConv, global_mean_pool\nfrom sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\nimport numpy as np\nimport os\nfrom datetime import datetime\n\nclass GAT_HR_Regressor(nn.Module):\n    \"\"\"\n    Graph Attention Network (GAT) for Heart Rate Regression.\n    \n    Architecture:\n    - 2 GAT layers with multi-head attention\n    - Batch normalization and dropout for regularization\n    - Final MLP for regression\n    \"\"\"\n    def __init__(self, in_channels, hidden_channels=64, heads=4, dropout=0.3):\n        super(GAT_HR_Regressor, self).__init__()\n        \n        # GAT Layer 1: multi-head attention\n        self.conv1 = GATConv(in_channels, hidden_channels, heads=heads, dropout=dropout)\n        self.bn1 = nn.BatchNorm1d(hidden_channels * heads)\n        \n        # GAT Layer 2: multi-head attention\n        self.conv2 = GATConv(hidden_channels * heads, hidden_channels, heads=heads, dropout=dropout)\n        self.bn2 = nn.BatchNorm1d(hidden_channels * heads)\n        \n        # Regression head (MLP)\n        self.fc1 = nn.Linear(hidden_channels * heads, hidden_channels)\n        self.fc2 = nn.Linear(hidden_channels, 1)\n        \n        self.dropout = dropout\n        \n    def forward(self, x, edge_index):\n        # GAT Layer 1\n        x = self.conv1(x, edge_index)\n        x = self.bn1(x)\n        x = F.elu(x)\n        x = F.dropout(x, p=self.dropout, training=self.training)\n        \n        # GAT Layer 2\n        x = self.conv2(x, edge_index)\n        x = self.bn2(x)\n        x = F.elu(x)\n        x = F.dropout(x, p=self.dropout, training=self.training)\n        \n        # Regression head\n        x = self.fc1(x)\n        x = F.relu(x)\n        x = F.dropout(x, p=self.dropout, training=self.training)\n        x = self.fc2(x)\n        \n        return x\n\ndef train_gnn_epoch(model, data, optimizer, device):\n    \"\"\"Train GNN for one epoch.\"\"\"\n    model.train()\n    optimizer.zero_grad()\n    \n    # Forward pass\n    out = model(data.x.to(device), data.edge_index.to(device))\n    loss = F.mse_loss(out, data.y.to(device))\n    \n    # Backward pass\n    loss.backward()\n    optimizer.step()\n    \n    return loss.item()\n\ndef evaluate_gnn(model, data, device):\n    \"\"\"Evaluate GNN on a dataset.\"\"\"\n    model.eval()\n    with torch.no_grad():\n        out = model(data.x.to(device), data.edge_index.to(device))\n        y_pred = out.cpu().numpy().squeeze()\n        y_true = data.y.cpu().numpy().squeeze()\n        \n        mae = mean_absolute_error(y_true, y_pred)\n        rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n        r2 = r2_score(y_true, y_pred)\n        \n    return mae, rmse, r2, y_pred\n\ndef train_gnn(train_data, test_data, epochs=500, lr=0.001, hidden_channels=64, heads=4, dropout=0.3, \n              save_checkpoints=True, checkpoint_freq=50):\n    \"\"\"\n    Train a GAT-based GNN for heart rate prediction with AUTO-SAVING checkpoints.\n    \n    Args:\n        save_checkpoints: If True, automatically saves model checkpoints during training\n        checkpoint_freq: Save checkpoint every N epochs (default: 50)\n    \"\"\"\n    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n    print(f\"Using device: {device}\")\n    \n    # Create checkpoint directory\n    if save_checkpoints:\n        os.makedirs('saved_models/checkpoints', exist_ok=True)\n        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n        checkpoint_dir = f'saved_models/checkpoints/training_{timestamp}'\n        os.makedirs(checkpoint_dir, exist_ok=True)\n        print(f\"ðŸ“ Checkpoints will be saved to: {checkpoint_dir}\")\n    \n    # Initialize model\n    in_channels = train_data.x.shape[1]\n    model = GAT_HR_Regressor(in_channels, hidden_channels, heads, dropout).to(device)\n    optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=5e-4)\n    \n    print(f\"\\nðŸš€ Training GAT-GNN for {epochs} epochs...\")\n    print(f\"Model parameters: hidden={hidden_channels}, heads={heads}, dropout={dropout}\")\n    if save_checkpoints:\n        print(f\"ðŸ’¾ Auto-save enabled: checkpoint every {checkpoint_freq} epochs\\n\")\n    \n    # Training loop\n    best_test_mae = float('inf')\n    best_model_state = None\n    \n    for epoch in range(1, epochs + 1):\n        loss = train_gnn_epoch(model, train_data, optimizer, device)\n        \n        if epoch % 25 == 0 or epoch == 1:\n            train_mae, train_rmse, train_r2, _ = evaluate_gnn(model, train_data, device)\n            test_mae, test_rmse, test_r2, _ = evaluate_gnn(model, test_data, device)\n            \n            print(f\"Epoch {epoch:03d} | Loss: {loss:.4f} | \"\n                  f\"Train MAE: {train_mae:.2f} | Test MAE: {test_mae:.2f} | \"\n                  f\"Test RÂ²: {test_r2:.3f}\")\n            \n            # Save best model\n            if test_mae < best_test_mae:\n                best_test_mae = test_mae\n                best_model_state = model.state_dict().copy()\n                \n                # Save best model checkpoint\n                if save_checkpoints:\n                    best_model_path = f'{checkpoint_dir}/best_model.pt'\n                    torch.save({\n                        'epoch': epoch,\n                        'model_state_dict': best_model_state,\n                        'optimizer_state_dict': optimizer.state_dict(),\n                        'test_mae': test_mae,\n                        'test_rmse': test_rmse,\n                        'test_r2': test_r2,\n                        'model_config': {\n                            'in_channels': in_channels,\n                            'hidden_channels': hidden_channels,\n                            'heads': heads,\n                            'dropout': dropout\n                        },\n                        'training_config': {'lr': lr, 'epochs': epochs, 'k_neighbors': 10},\n                        'scaler': scaler\n                    }, best_model_path)\n        \n        # Periodic checkpoint save\n        if save_checkpoints and epoch % checkpoint_freq == 0:\n            checkpoint_path = f'{checkpoint_dir}/checkpoint_epoch_{epoch}.pt'\n            torch.save({\n                'epoch': epoch,\n                'model_state_dict': model.state_dict(),\n                'optimizer_state_dict': optimizer.state_dict(),\n                'best_test_mae': best_test_mae,\n                'model_config': {\n                    'in_channels': in_channels,\n                    'hidden_channels': hidden_channels,\n                    'heads': heads,\n                    'dropout': dropout\n                },\n                'training_config': {'lr': lr, 'epochs': epochs, 'k_neighbors': 10},\n                'scaler': scaler\n            }, checkpoint_path)\n            print(f\"ðŸ’¾ Checkpoint saved: epoch {epoch}\")\n    \n    # Load best model\n    model.load_state_dict(best_model_state)\n    \n    # Save final model\n    if save_checkpoints:\n        final_model_path = f'{checkpoint_dir}/final_model_complete.pt'\n        torch.save({\n            'model_state_dict': best_model_state,\n            'model_config': {\n                'in_channels': in_channels,\n                'hidden_channels': hidden_channels,\n                'heads': heads,\n                'dropout': dropout\n            },\n            'training_config': {'lr': lr, 'epochs': epochs, 'k_neighbors': 10},\n            'scaler': scaler,\n            'feature_info': {\n                'num_features': X_train.shape[1],\n                'num_train_samples': len(X_train),\n                'num_test_samples': len(X_test)\n            },\n            'timestamp': timestamp\n        }, final_model_path)\n        print(f\"\\nðŸ’¾ Final model saved to: {final_model_path}\")\n    \n    # Final evaluation\n    print(\"\\n\" + \"=\"*70)\n    print(\"âœ… Training Complete - Final Test Performance\")\n    print(\"=\"*70)\n    test_mae, test_rmse, test_r2, y_pred = evaluate_gnn(model, test_data, device)\n    print(f\"MAE:  {test_mae:.2f} bpm\")\n    print(f\"RMSE: {test_rmse:.2f} bpm\")\n    print(f\"RÂ²:   {test_r2:.3f}\")\n    print(\"=\"*70)\n    \n    if save_checkpoints:\n        print(f\"\\nðŸ“¦ All files saved in: {checkpoint_dir}\")\n        print(\"   - best_model.pt (updated whenever performance improves)\")\n        print(\"   - checkpoint_epoch_*.pt (periodic saves)\")\n        print(\"   - final_model_complete.pt (ready to share with your group)\")\n    \n    return model, y_pred\n\n# Train the GNN model with AUTO-SAVING enabled\n# âš ï¸ IMPORTANT: Checkpoints are saved automatically every 50 epochs!\ngnn_model, y_pred_gnn = train_gnn(\n    train_data, \n    test_data, \n    epochs=500,\n    lr=0.001,\n    hidden_channels=64,\n    heads=4,\n    dropout=0.3,\n    save_checkpoints=True,  # AUTO-SAVE ENABLED!\n    checkpoint_freq=50       # Save every 50 epochs\n)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import itertools\nimport torch\n\ndef tune_gnn_hyperparameters(train_data, test_data, epochs=250):\n    \"\"\"\n    Grid search hyperparameter tuning for GAT-GNN.\n    \n    Tests different combinations of:\n    - hidden_channels: model capacity\n    - heads: number of attention heads\n    - dropout: regularization strength\n    - learning_rate: optimization step size\n    \"\"\"\n    \n    param_grid = {\n        'hidden_channels': [32, 64, 128],\n        'heads': [2, 4, 8],\n        'dropout': [0.2, 0.3, 0.5],\n        'lr': [0.001, 0.0005]\n    }\n    \n    print(\"ðŸ” Starting GNN Hyperparameter Tuning...\")\n    print(f\"Testing {np.prod([len(v) for v in param_grid.values()])} combinations\\n\")\n    \n    best_mae = float('inf')\n    best_params = None\n    results = []\n    \n    # Grid search\n    for hidden_channels, heads, dropout, lr in itertools.product(\n        param_grid['hidden_channels'],\n        param_grid['heads'],\n        param_grid['dropout'],\n        param_grid['lr']\n    ):\n        print(f\"Testing: hidden={hidden_channels}, heads={heads}, dropout={dropout}, lr={lr}\")\n        \n        try:\n            # Train model with current hyperparameters\n            device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n            in_channels = train_data.x.shape[1]\n            \n            model = GAT_HR_Regressor(in_channels, hidden_channels, heads, dropout).to(device)\n            optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=5e-4)\n            \n            # Train for specified epochs\n            for epoch in range(epochs):\n                train_gnn_epoch(model, train_data, optimizer, device)\n            \n            # Evaluate on test set\n            test_mae, test_rmse, test_r2, _ = evaluate_gnn(model, test_data, device)\n            \n            results.append({\n                'hidden_channels': hidden_channels,\n                'heads': heads,\n                'dropout': dropout,\n                'lr': lr,\n                'test_mae': test_mae,\n                'test_rmse': test_rmse,\n                'test_r2': test_r2\n            })\n            \n            print(f\"  â†’ MAE: {test_mae:.2f}, RMSE: {test_rmse:.2f}, RÂ²: {test_r2:.3f}\\n\")\n            \n            # Track best model\n            if test_mae < best_mae:\n                best_mae = test_mae\n                best_params = {\n                    'hidden_channels': hidden_channels,\n                    'heads': heads,\n                    'dropout': dropout,\n                    'lr': lr\n                }\n                \n        except Exception as e:\n            print(f\"  âš ï¸ Failed with error: {e}\\n\")\n            continue\n    \n    print(\"\\n\" + \"=\"*70)\n    print(\"âœ… Best GNN Hyperparameters Found:\")\n    print(\"=\"*70)\n    for key, value in best_params.items():\n        print(f\"{key}: {value}\")\n    print(f\"\\nBest Test MAE: {best_mae:.2f} bpm\")\n    print(\"=\"*70)\n    \n    return best_params, results\n\n# Run hyperparameter tuning (âš ï¸ This will take some time)\n# Comment out if you want to skip tuning\nbest_params, tuning_results = tune_gnn_hyperparameters(train_data, test_data, epochs=250)\n\n# Train final model with best hyperparameters\nprint(\"\\nðŸš€ Training final GNN model with best hyperparameters...\")\nbest_gnn_model, y_pred_best_gnn = train_gnn(\n    train_data,\n    test_data,\n    epochs=500,  # Increased from 200 to 500 for longer training\n    lr=best_params['lr'],\n    hidden_channels=best_params['hidden_channels'],\n    heads=best_params['heads'],\n    dropout=best_params['dropout']\n)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize GNN predictions\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "def evaluate_model(y_test, y_pred, sample_range=500, title_prefix=\"GNN\"):\n",
    "    # 1. Scatter Plot\n",
    "    plt.figure(figsize=(6,6))\n",
    "    sns.scatterplot(x=y_test, y=y_pred, alpha=0.4)\n",
    "    plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--')\n",
    "    plt.xlabel(\"Ground Truth HR (bpm)\")\n",
    "    plt.ylabel(\"Predicted HR (bpm)\")\n",
    "    plt.title(f\"{title_prefix} - Predicted vs Ground Truth HR\")\n",
    "    plt.show()\n",
    "    \n",
    "    # 2. Time Series (first N samples)\n",
    "    plt.figure(figsize=(12,4))\n",
    "    plt.plot(y_test[:sample_range], label=\"Ground Truth\", lw=2)\n",
    "    plt.plot(y_pred[:sample_range], label=\"Predicted\", lw=2, alpha=0.7)\n",
    "    plt.xlabel(\"Sample Index\")\n",
    "    plt.ylabel(\"Heart Rate (bpm)\")\n",
    "    plt.title(f\"{title_prefix} - Prediction vs Ground Truth (first {sample_range} samples)\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "    # 3. Error Distribution\n",
    "    errors = y_pred - y_test\n",
    "    plt.figure(figsize=(6,4))\n",
    "    sns.histplot(errors, bins=50, kde=True)\n",
    "    plt.xlabel(\"Prediction Error (bpm)\")\n",
    "    plt.title(f\"{title_prefix} - Error Distribution\")\n",
    "    plt.show()\n",
    "    \n",
    "    # 4. Bland-Altman Plot\n",
    "    mean_hr = (y_test + y_pred) / 2\n",
    "    diff_hr = y_pred - y_test\n",
    "    plt.figure(figsize=(6,4))\n",
    "    plt.scatter(mean_hr, diff_hr, alpha=0.4)\n",
    "    plt.axhline(np.mean(diff_hr), color='red', linestyle='--', label=f'Mean: {np.mean(diff_hr):.2f}')\n",
    "    plt.axhline(np.mean(diff_hr) + 1.96*np.std(diff_hr), color='gray', linestyle='--', label=f'+1.96 SD: {np.mean(diff_hr) + 1.96*np.std(diff_hr):.2f}')\n",
    "    plt.axhline(np.mean(diff_hr) - 1.96*np.std(diff_hr), color='gray', linestyle='--', label=f'-1.96 SD: {np.mean(diff_hr) - 1.96*np.std(diff_hr):.2f}')\n",
    "    plt.xlabel(\"Mean HR (bpm)\")\n",
    "    plt.ylabel(\"Difference (Pred - True, bpm)\")\n",
    "    plt.title(f\"{title_prefix} - Bland-Altman Plot\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "# Run evaluation on GNN predictions\n",
    "evaluate_model(y_test, y_pred_gnn, sample_range=500, title_prefix=\"GAT-GNN\")\n",
    "\n",
    "# If you ran hyperparameter tuning, evaluate the best model\n",
    "# evaluate_model(y_test, y_pred_best_gnn, sample_range=500, title_prefix=\"Best GAT-GNN\")"
   ]
  },
  {
   "cell_type": "code",
   "source": "# ============================================================================\n# SAVE TRAINED GNN MODEL\n# Run this cell to save your trained model for sharing with your group\n# ============================================================================\n\nimport torch\nimport pickle\nimport os\nfrom datetime import datetime\n\n# Create a models directory if it doesn't exist\nos.makedirs('saved_models', exist_ok=True)\n\n# Get timestamp for versioning\ntimestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n\n# Determine which model to save\n# If you ran hyperparameter tuning, save best_gnn_model, otherwise save gnn_model\ntry:\n    model_to_save = best_gnn_model\n    model_name = \"best_gnn_model\"\n    config = best_params  # Use the best hyperparameters found during tuning\n    print(\"ðŸ“¦ Saving hyperparameter-tuned model...\")\nexcept NameError:\n    model_to_save = gnn_model\n    model_name = \"gnn_model\"\n    config = {\n        'hidden_channels': 64,\n        'heads': 4,\n        'dropout': 0.3,\n        'lr': 0.001\n    }\n    print(\"ðŸ“¦ Saving base GNN model...\")\n\n# Get model architecture info\nin_channels = train_data.x.shape[1]\n\n# Save complete model package\nmodel_package = {\n    'model_state_dict': model_to_save.state_dict(),\n    'model_config': {\n        'in_channels': in_channels,\n        'hidden_channels': config['hidden_channels'],\n        'heads': config['heads'],\n        'dropout': config['dropout']\n    },\n    'training_config': {\n        'lr': config.get('lr', 0.001),\n        'epochs': 500,\n        'k_neighbors': 10\n    },\n    'scaler': scaler,  # Save the StandardScaler for feature normalization\n    'feature_info': {\n        'num_features': X_train.shape[1],\n        'num_train_samples': len(X_train),\n        'num_test_samples': len(X_test)\n    },\n    'timestamp': timestamp\n}\n\n# Save the complete package\nmodel_path = f'saved_models/gat_hr_model_complete_{timestamp}.pt'\ntorch.save(model_package, model_path)\nprint(f\"âœ… Complete model package saved to: {model_path}\")\n\n# Also save a lightweight version (just weights) for easier sharing\nweights_path = f'saved_models/gat_hr_model_weights_{timestamp}.pt'\ntorch.save(model_to_save.state_dict(), weights_path)\nprint(f\"âœ… Model weights saved to: {weights_path}\")\n\n# Save model configuration as a readable text file\nconfig_path = f'saved_models/model_config_{timestamp}.txt'\nwith open(config_path, 'w') as f:\n    f.write(\"=\"*70 + \"\\n\")\n    f.write(\"GAT-GNN Heart Rate Prediction Model Configuration\\n\")\n    f.write(\"=\"*70 + \"\\n\\n\")\n    f.write(f\"Saved on: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\\n\\n\")\n    f.write(\"Model Architecture:\\n\")\n    f.write(f\"  - Input features: {in_channels}\\n\")\n    f.write(f\"  - Hidden channels: {config['hidden_channels']}\\n\")\n    f.write(f\"  - Attention heads: {config['heads']}\\n\")\n    f.write(f\"  - Dropout: {config['dropout']}\\n\\n\")\n    f.write(\"Training Configuration:\\n\")\n    f.write(f\"  - Learning rate: {config.get('lr', 0.001)}\\n\")\n    f.write(f\"  - Epochs: 500\\n\")\n    f.write(f\"  - K-neighbors: 10\\n\\n\")\n    f.write(\"Dataset Info:\\n\")\n    f.write(f\"  - Training samples: {len(X_train)}\\n\")\n    f.write(f\"  - Test samples: {len(X_test)}\\n\")\n    f.write(f\"  - Feature dimensions: {X_train.shape[1]}\\n\")\n    f.write(\"=\"*70 + \"\\n\")\n\nprint(f\"âœ… Configuration saved to: {config_path}\")\n\nprint(\"\\n\" + \"=\"*70)\nprint(\"ðŸ“ FILES TO SHARE WITH YOUR GROUP:\")\nprint(\"=\"*70)\nprint(f\"1. {model_path}\")\nprint(f\"   â†’ Complete model package (includes everything)\")\nprint(f\"\\n2. {weights_path}\")\nprint(f\"   â†’ Just the model weights (lightweight)\")\nprint(f\"\\n3. {config_path}\")\nprint(f\"   â†’ Human-readable configuration\")\nprint(\"\\n4. saved_models/model_loader.py\")\nprint(\"   â†’ Script to load and use the model (will be created next)\")\nprint(\"=\"*70)\n\n# Evaluate final model performance for documentation\nprint(\"\\n\" + \"=\"*70)\nprint(\"FINAL MODEL PERFORMANCE:\")\nprint(\"=\"*70)\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\ntest_mae, test_rmse, test_r2, _ = evaluate_gnn(model_to_save, test_data, device)\nprint(f\"Test MAE:  {test_mae:.2f} bpm\")\nprint(f\"Test RMSE: {test_rmse:.2f} bpm\")\nprint(f\"Test RÂ²:   {test_r2:.3f}\")\nprint(\"=\"*70)",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "transECG",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}